{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import logical_and as _and\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.5 s, sys: 523 ms, total: 15 s\n",
      "Wall time: 18.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dates = [['event_datetime_m'], ['date_time'], ['create_datetime']]\n",
    "X_train = pd.read_csv('data/champ_10_datas/impressions.csv', \n",
    "                          parse_dates=dates[0], dayfirst=True, infer_datetime_format=True)\n",
    "X_test = pd.read_csv('data/champ_10_datas/test.csv', \n",
    "                   parse_dates=dates[0], dayfirst=True, infer_datetime_format=True)\n",
    "show_data = pd.read_csv('data/champ_10_datas/show_data.csv').drop_duplicates('id_show')\n",
    "show_rating = pd.read_csv('data/champ_10_datas/show_rating.csv', \n",
    "                          parse_dates=dates[1], dayfirst=True, infer_datetime_format=True)\n",
    "client_data = pd.read_csv('data/champ_10_datas/client_data.csv', \n",
    "                          parse_dates=dates[2], dayfirst=True, \n",
    "                          infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Отрицательные значения даты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 53.9 ms, sys: 60 µs, total: 53.9 ms\n",
      "Wall time: 80.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "client_data.drop('create_datetime', axis=1, inplace=True)\n",
    "neg_idx = client_data['age'] < 0\n",
    "client_data.loc[neg_idx, 'age'] = -client_data.loc[neg_idx, 'age']\n",
    "\n",
    "show_data.drop(['child_genre_id', 'parent_genre_id'], axis=1, inplace=True)\n",
    "show_data.drop('IdBuilding', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Сгенерируем ctr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ctr_generate(train, test, groupby):\n",
    "    val_1 = train.loc[train['event_datetime_m'] < dt.datetime(2017, 2, 1)]\n",
    "    val_2 = train.loc[_and(train['event_datetime_m'] >= dt.datetime(2017, 2, 1), \n",
    "                          train['event_datetime_m'] < dt.datetime(2017, 3, 1))]\n",
    "    val_3 = train.loc[train['event_datetime_m'] >= dt.datetime(2017, 3, 1)]\n",
    "    \n",
    "    val_12 = val_1.append(val_2)\n",
    "    val_23 = val_2.append(val_3)\n",
    "    val_13 = val_1.append(val_3)\n",
    "    \n",
    "    ctr12 = val_12.groupby([groupby])[['is_clicked']].mean()\n",
    "    ctr12.columns = ['ctr_' + groupby]\n",
    "    ctr12[groupby] = ctr12.index\n",
    "    val_3 = val_3.merge(ctr12, on=[groupby], how='left')\n",
    "    \n",
    "    ctr23 = val_23.groupby([groupby])[['is_clicked']].mean()\n",
    "    ctr23.columns = ['ctr_' + groupby]\n",
    "    ctr23[groupby] = ctr23.index\n",
    "    val_1 = val_1.merge(ctr23, on=[groupby], how='left')\n",
    "    \n",
    "    ctr13 = val_13.groupby([groupby])[['is_clicked']].mean()\n",
    "    ctr13.columns = ['ctr_' + groupby]\n",
    "    ctr13[groupby] = ctr13.index\n",
    "    val_2 = val_2.merge(ctr13, on=[groupby], how='left')\n",
    "    \n",
    "    ctr12.columns = ['ctr12_' + groupby, groupby]\n",
    "    ctr23.columns = ['ctr23_' + groupby, groupby]\n",
    "    ctr13.columns = ['ctr13_' + groupby, groupby]\n",
    "    \n",
    "    test = test.merge(ctr12, on=[groupby], how='left')\n",
    "    test = test.merge(ctr23, on=[groupby], how='left')\n",
    "    test = test.merge(ctr13, on=[groupby], how='left')\n",
    "    \n",
    "    del ctr12\n",
    "    del ctr13\n",
    "    del ctr23\n",
    "    \n",
    "    test['ctr12_' + groupby].fillna(0, inplace=True)\n",
    "    test['ctr23_' + groupby].fillna(0, inplace=True)\n",
    "    test['ctr13_' + groupby].fillna(0, inplace=True)\n",
    "    \n",
    "    test['ctr_' + groupby] = (test['ctr12_' + groupby] + 8 * test['ctr23_' + groupby] + 4 * test['ctr13_' + groupby]) / 13\n",
    "    test.drop('ctr12_' + groupby, inplace=True, axis=1)\n",
    "    test.drop('ctr23_' + groupby, inplace=True, axis=1)\n",
    "    test.drop('ctr13_' + groupby, inplace=True, axis=1)\n",
    "    \n",
    "    train = val_1.append(val_2).append(val_3)\n",
    "    del val_1\n",
    "    del val_2\n",
    "    del val_3\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.69 s, sys: 1.51 s, total: 10.2 s\n",
      "Wall time: 10.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train, X_test = ctr_generate(X_train, X_test, 'id_show')\n",
    "X_train, X_test = ctr_generate(X_train, X_test, 'id_user')\n",
    "\n",
    "show_data['organizer_id'] = show_data['organizer_id'].fillna(0).astype('int64')\n",
    "X_train = X_train.merge(show_data, on='id_show', how='left')\n",
    "X_test = X_test.merge(show_data, on='id_show', how='left')\n",
    "del show_data\n",
    "\n",
    "X_train, X_test = ctr_generate(X_train, X_test, 'organizer_id')\n",
    "\n",
    "show_rating = show_rating.groupby('id_show').mean().reset_index()\n",
    "X_train = X_train.merge(show_rating, how='left', on='id_show')\n",
    "X_test = X_test.merge(show_rating, how='left', on='id_show')\n",
    "del show_rating\n",
    "\n",
    "X_train = X_train.merge(client_data, how='left', on='id_user')\n",
    "X_test = X_test.merge(client_data, how='left', on='id_user')\n",
    "del client_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13 s, sys: 818 ms, total: 13.8 s\n",
      "Wall time: 13.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train['ones'] = np.ones(len(X_train), dtype=np.int32)\n",
    "\n",
    "X_test['ones'] = np.ones(len(X_test), dtype=np.int32)\n",
    "\n",
    "show_dt_count = X_train.groupby(['id_show', 'event_datetime_m'])[['ones']].sum()\n",
    "show_dt_count.columns = ['show_dt_count']\n",
    "show_dt_count.reset_index(inplace=True)\n",
    "X_train = X_train.merge(show_dt_count, on=['id_show', 'event_datetime_m'], how='left')\n",
    "\n",
    "show_dt_count = X_test.groupby(['id_show', 'event_datetime_m'])[['ones']].sum()\n",
    "show_dt_count.columns = ['show_dt_count']\n",
    "show_dt_count.reset_index(inplace=True)\n",
    "X_test = X_test.merge(show_dt_count, on=['id_show', 'event_datetime_m'], how='left')\n",
    "del show_dt_count\n",
    "\n",
    "\n",
    "user_dt_count = X_train.groupby(['id_user', 'event_datetime_m'])[['ones']].sum()\n",
    "user_dt_count.columns = ['user_dt_count']\n",
    "user_dt_count.reset_index(inplace=True)\n",
    "X_train = X_train.merge(user_dt_count, on=['id_user', 'event_datetime_m'], how='left')\n",
    "\n",
    "user_dt_count = X_test.groupby(['id_user', 'event_datetime_m'])[['ones']].sum()\n",
    "user_dt_count.columns = ['user_dt_count']\n",
    "user_dt_count.reset_index(inplace=True)\n",
    "X_test = X_test.merge(user_dt_count, on=['id_user', 'event_datetime_m'], how='left')\n",
    "del user_dt_count\n",
    "\n",
    "\n",
    "show_user_dt_count = X_train.groupby(['id_user', 'id_show', 'event_datetime_m'])[['ones']].sum()\n",
    "show_user_dt_count.columns = ['show_user_dt_count']\n",
    "show_user_dt_count.reset_index(inplace=True)\n",
    "X_train = X_train.merge(show_user_dt_count, on=['id_user', 'id_show', 'event_datetime_m'], how='left')\n",
    "\n",
    "show_user_dt_count = X_test.groupby(['id_user', 'id_show', 'event_datetime_m'])[['ones']].sum()\n",
    "show_user_dt_count.columns = ['show_user_dt_count']\n",
    "show_user_dt_count.reset_index(inplace=True)\n",
    "X_test = X_test.merge(show_user_dt_count, on=['id_user', 'id_show', 'event_datetime_m'], how='left')\n",
    "del show_user_dt_count\n",
    "\n",
    "\n",
    "X_train.drop('ones', inplace=True, axis=1)\n",
    "X_test.drop('ones', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.2 s, sys: 1.4 s, total: 13.6 s\n",
      "Wall time: 13.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "rank_i = 'rank' + str(1)\n",
    "X_train.loc[X_train['rank'] == 1, rank_i] = 1\n",
    "X_train.loc[X_train['rank'] != 1, rank_i] = 0\n",
    "X_train[rank_i] = X_train[rank_i].astype('int8')\n",
    "    \n",
    "X_test.loc[X_test['rank'] == 1, rank_i] = 1\n",
    "X_test.loc[X_test['rank'] != 1, rank_i] = 0\n",
    "X_test[rank_i] = X_test[rank_i].astype('int8')\n",
    "    \n",
    "show_dt_count = X_train.groupby(['id_show', 'event_datetime_m'])[[rank_i]].sum()\n",
    "show_dt_count.columns = [rank_i + '_show_dt_count']\n",
    "show_dt_count.reset_index(inplace=True)\n",
    "X_train = X_train.merge(show_dt_count, on=['id_show', 'event_datetime_m'], how='left')\n",
    "    \n",
    "show_dt_count = X_test.groupby(['id_show', 'event_datetime_m'])[[rank_i]].sum()\n",
    "show_dt_count.columns = [rank_i + '_show_dt_count']\n",
    "show_dt_count.reset_index(inplace=True)\n",
    "X_test = X_test.merge(show_dt_count, on=['id_show', 'event_datetime_m'], how='left')\n",
    "del show_dt_count\n",
    "    \n",
    "    \n",
    "user_dt_count = X_train.groupby(['id_user', 'event_datetime_m'])[[rank_i]].sum()\n",
    "user_dt_count.columns = [rank_i + '_user_dt_count']\n",
    "user_dt_count.reset_index(inplace=True)\n",
    "X_train = X_train.merge(user_dt_count, on=['id_user', 'event_datetime_m'], how='left')\n",
    "    \n",
    "user_dt_count = X_test.groupby(['id_user', 'event_datetime_m'])[[rank_i]].sum()\n",
    "user_dt_count.columns = [rank_i + '_user_dt_count']\n",
    "user_dt_count.reset_index(inplace=True)\n",
    "X_test = X_test.merge(user_dt_count, on=['id_user', 'event_datetime_m'], how='left')\n",
    "del user_dt_count\n",
    "\n",
    "\n",
    "show_user_dt_count = X_train.groupby(['id_user', 'id_show', 'event_datetime_m'])[[rank_i]].sum()\n",
    "show_user_dt_count.columns = [rank_i + '_show_user_dt_count']\n",
    "show_user_dt_count.reset_index(inplace=True)\n",
    "X_train = X_train.merge(show_user_dt_count, on=['id_user', 'id_show', 'event_datetime_m'], how='left')\n",
    "\n",
    "show_user_dt_count = X_test.groupby(['id_user', 'id_show', 'event_datetime_m'])[[rank_i]].sum()\n",
    "show_user_dt_count.columns = [rank_i + '_show_user_dt_count']\n",
    "show_user_dt_count.reset_index(inplace=True)\n",
    "X_test = X_test.merge(show_user_dt_count, on=['id_user', 'id_show', 'event_datetime_m'], how='left')\n",
    "del show_user_dt_count\n",
    "    \n",
    "X_train.drop(rank_i, inplace=True, axis=1)\n",
    "X_test.drop(rank_i, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26.3 s, sys: 7.22 s, total: 33.5 s\n",
      "Wall time: 33.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "all_data = X_train.append(X_test)\n",
    "all_data.index = np.arange(len(all_data))\n",
    "del X_train\n",
    "del X_test\n",
    "all_data['ones'] = np.ones(len(all_data), dtype=np.int32)\n",
    "\n",
    "tmp_sum = all_data.sort_values('event_datetime_m', \n",
    "                               ascending=True).groupby(['id_show', 'event_datetime_m'])[['ones']].cumsum()\n",
    "tmp_sum.columns = ['sum_open_show_event_datetime']\n",
    "all_data.loc[tmp_sum.index, 'sum_open_show_event_datetime'] = tmp_sum['sum_open_show_event_datetime'].astype('int32')\n",
    "\n",
    "tmp_sum = all_data.sort_values('event_datetime_m', \n",
    "                               ascending=False).groupby(['id_show', 'event_datetime_m'])[['ones']].cumsum()\n",
    "tmp_sum.columns = ['sum_open_show_event_datetime_2']\n",
    "all_data.loc[tmp_sum.index, 'sum_open_show_event_datetime_2'] = tmp_sum['sum_open_show_event_datetime_2'].astype('int32')\n",
    "\n",
    "tmp_sum = all_data.sort_values('event_datetime_m', \n",
    "                               ascending=True).groupby(['id_user', 'event_datetime_m'])[['ones']].cumsum()\n",
    "tmp_sum.columns = ['sum_open_user_event_datetime']\n",
    "all_data.loc[tmp_sum.index, 'sum_open_user_event_datetime'] = tmp_sum['sum_open_user_event_datetime'].astype('int32')\n",
    "\n",
    "tmp_sum = all_data.sort_values('event_datetime_m', \n",
    "                               ascending=False).groupby(['id_user', 'event_datetime_m'])[['ones']].cumsum()\n",
    "tmp_sum.columns = ['sum_open_user_event_datetime_2']\n",
    "all_data.loc[tmp_sum.index, 'sum_open_user_event_datetime_2'] = tmp_sum['sum_open_user_event_datetime_2'].astype('int32')\n",
    "\n",
    "tmp_sum = all_data.sort_values('event_datetime_m', \n",
    "                               ascending=True).groupby(['id_user', 'id_show', 'event_datetime_m'])[['ones']].cumsum()\n",
    "tmp_sum.columns = ['sum_open_user_show_event']\n",
    "all_data.loc[tmp_sum.index, 'sum_open_user_show_event'] = tmp_sum['sum_open_user_show_event'].astype('int32')\n",
    "\n",
    "tmp_sum = all_data.sort_values('event_datetime_m', \n",
    "                               ascending=False).groupby(['id_user', 'id_show', 'event_datetime_m'])[['ones']].cumsum()\n",
    "tmp_sum.columns = ['sum_open_user_show_event_2']\n",
    "all_data.loc[tmp_sum.index, 'sum_open_user_show_event_2'] = tmp_sum['sum_open_user_show_event_2'].astype('int32')\n",
    "all_data.drop('ones', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27.2 s, sys: 7.94 s, total: 35.2 s\n",
      "Wall time: 35.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rank_i = 'rank' + str(1)\n",
    "all_data.loc[all_data['rank'] == 1, rank_i] = 1\n",
    "all_data.loc[all_data['rank'] != 1, rank_i] = 0\n",
    "all_data[rank_i] = all_data[rank_i].astype('int32')\n",
    "    \n",
    "user_dt = all_data.sort_values('event_datetime_m', \n",
    "                                   ascending=True).groupby(['id_user', 'event_datetime_m'])[[rank_i]].cumsum()\n",
    "user_dt.columns = [rank_i + '_user_dt']\n",
    "all_data.loc[user_dt.index, rank_i + '_user_dt'] = user_dt.astype('int32')\n",
    "    \n",
    "user_dt = all_data.sort_values('event_datetime_m', \n",
    "                                   ascending=False).groupby(['id_user', 'event_datetime_m'])[[rank_i]].cumsum()\n",
    "user_dt.columns = [rank_i + '_user_dt_2']\n",
    "all_data.loc[user_dt.index, rank_i + '_user_dt_2'] = user_dt.astype('int32')\n",
    "del user_dt\n",
    "\n",
    "\n",
    "show_dt = all_data.sort_values('event_datetime_m', \n",
    "                                   ascending=True).groupby(['id_show', 'event_datetime_m'])[[rank_i]].cumsum()\n",
    "show_dt.columns = [rank_i + '_show_dt']\n",
    "all_data.loc[show_dt.index, rank_i + '_show_dt'] = show_dt.astype('int32')\n",
    "    \n",
    "show_dt = all_data.sort_values('event_datetime_m', \n",
    "                                   ascending=False).groupby(['id_show', 'event_datetime_m'])[[rank_i]].cumsum()\n",
    "show_dt.columns = [rank_i + '_show_dt_2']\n",
    "all_data.loc[show_dt.index, rank_i + '_show_dt_2'] = show_dt.astype('int32')\n",
    "del show_dt\n",
    "    \n",
    "\n",
    "user_show_dt = all_data.sort_values('event_datetime_m', \n",
    "                                   ascending=True).groupby(['id_user', \n",
    "                                                            'id_show', \n",
    "                                                            'event_datetime_m'])[[rank_i]].cumsum()\n",
    "user_show_dt.columns = [rank_i + '_user_show_dt']\n",
    "all_data.loc[user_show_dt.index, rank_i + '_user_show_dt'] = user_show_dt.astype('int32')\n",
    "    \n",
    "user_show_dt = all_data.sort_values('event_datetime_m', \n",
    "                                   ascending=False).groupby(['id_user', \n",
    "                                                             'id_show', \n",
    "                                                             'event_datetime_m'])[[rank_i]].cumsum()\n",
    "user_show_dt.columns = [rank_i + '_user_show_dt_2']\n",
    "all_data.loc[user_show_dt.index, rank_i + '_user_show_dt_2'] = user_show_dt.astype('int32')\n",
    "del user_show_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 907 ms, sys: 614 ms, total: 1.52 s\n",
      "Wall time: 18.8 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/root/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_mask = all_data['id'].notnull()\n",
    "X_test = all_data.loc[test_mask]\n",
    "X_train = all_data.loc[~test_mask]\n",
    "X_train.drop('id', inplace=True, axis=1)\n",
    "X_test.drop('is_clicked', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 237 ms, sys: 103 ms, total: 340 ms\n",
      "Wall time: 358 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_train = X_train['is_clicked'].values.astype('int32')\n",
    "X_train.drop('is_clicked', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.23 s, sys: 0 ns, total: 1.23 s\n",
      "Wall time: 1.29 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train['sex'] = X_train['sex'].apply(lambda x: x == 'female')\n",
    "X_test['sex'] = X_test['sex'].apply(lambda x: x == 'female')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 365 ms, sys: 55.8 ms, total: 421 ms\n",
      "Wall time: 633 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_val = y_train[X_train['event_datetime_m'] > dt.datetime(2017, 3, 10)]\n",
    "y_train = y_train[X_train['event_datetime_m'] <= dt.datetime(2017, 3, 10)]\n",
    "X_val = X_train.loc[X_train['event_datetime_m'] > dt.datetime(2017, 3, 10)]\n",
    "X_train = X_train.loc[X_train['event_datetime_m'] <= dt.datetime(2017, 3, 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.5 s, sys: 239 ms, total: 19.7 s\n",
      "Wall time: 19.9 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train['event_datetime_m'] = X_train['event_datetime_m'].apply(lambda x: x.day)\n",
    "X_val['event_datetime_m'] = X_val['event_datetime_m'].apply(lambda x: x.day)\n",
    "X_test['event_datetime_m'] = X_test['event_datetime_m'].apply(lambda x: x.day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 109 ms, sys: 8.23 ms, total: 118 ms\n",
      "Wall time: 117 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train.index = np.arange(len(X_train))\n",
    "X_val.index = np.arange(len(X_val))\n",
    "X_test.index = np.arange(len(X_test))\n",
    "\n",
    "id_test = X_test['id'].values.astype('int')\n",
    "X_test.drop('id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'age_category', 'ctr_id_show', 'ctr_id_user', 'ctr_organizer_id',\n",
       "       'duration', 'event_datetime_m', 'id_show', 'id_user', 'organizer_id',\n",
       "       'rank', 'rank1_show_dt_count', 'rank1_show_user_dt_count',\n",
       "       'rank1_user_dt_count', 'rating', 'rating_count', 'review_count', 'sex',\n",
       "       'show_dt_count', 'show_maxprice', 'show_meanprice', 'show_minprice',\n",
       "       'show_stdprice', 'show_user_dt_count', 'user_dt_count',\n",
       "       'sum_open_show_event_datetime', 'sum_open_show_event_datetime_2',\n",
       "       'sum_open_user_event_datetime', 'sum_open_user_event_datetime_2',\n",
       "       'sum_open_user_show_event', 'sum_open_user_show_event_2', 'rank1',\n",
       "       'rank1_user_dt', 'rank1_user_dt_2', 'rank1_show_dt', 'rank1_show_dt_2',\n",
       "       'rank1_user_show_dt', 'rank1_user_show_dt_2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "use_cols = ['age', 'age_category', 'ctr_id_show', 'ctr_id_user', 'ctr_organizer_id',\n",
    "       'duration', 'rank', 'rank1_show_dt_count', 'rank1_show_user_dt_count',\n",
    "       'rank1_user_dt_count', 'rating',\n",
    "       'rating_count', 'review_count', 'sex', 'show_dt_count', 'show_maxprice',\n",
    "       'show_meanprice', 'show_minprice', 'show_stdprice',\n",
    "       'show_user_dt_count', 'user_dt_count',\n",
    "       'sum_open_show_event_datetime',\n",
    "       'sum_open_show_event_datetime_2', 'sum_open_user_event_datetime',\n",
    "       'sum_open_user_event_datetime_2', 'sum_open_user_show_event',\n",
    "       'sum_open_user_show_event_2', 'rank1_user_dt', 'rank1_user_dt_2', 'rank1_show_dt', 'rank1_show_dt_2',\n",
    "       'rank1_user_show_dt', 'rank1_user_show_dt_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtrain = lgb.Dataset(X_train[use_cols], label=y_train, silent=True)\n",
    "dvalid = dtrain.create_valid(X_val[use_cols], label=y_val, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 25 rounds.\n",
      "[25]\ttraining's binary_logloss: 0.212629\tvalid_1's binary_logloss: 0.214642\n",
      "[50]\ttraining's binary_logloss: 0.11997\tvalid_1's binary_logloss: 0.122301\n",
      "[75]\ttraining's binary_logloss: 0.0983833\tvalid_1's binary_logloss: 0.100895\n",
      "[100]\ttraining's binary_logloss: 0.0931387\tvalid_1's binary_logloss: 0.0956932\n",
      "[125]\ttraining's binary_logloss: 0.0917728\tvalid_1's binary_logloss: 0.0943862\n",
      "[150]\ttraining's binary_logloss: 0.0911145\tvalid_1's binary_logloss: 0.0938335\n",
      "[175]\ttraining's binary_logloss: 0.0905999\tvalid_1's binary_logloss: 0.0934033\n",
      "[200]\ttraining's binary_logloss: 0.0902563\tvalid_1's binary_logloss: 0.0931211\n",
      "[225]\ttraining's binary_logloss: 0.0899696\tvalid_1's binary_logloss: 0.0928578\n",
      "[250]\ttraining's binary_logloss: 0.0896353\tvalid_1's binary_logloss: 0.0925961\n",
      "[275]\ttraining's binary_logloss: 0.0894202\tvalid_1's binary_logloss: 0.0924868\n",
      "[300]\ttraining's binary_logloss: 0.0891855\tvalid_1's binary_logloss: 0.0923366\n",
      "[325]\ttraining's binary_logloss: 0.0889936\tvalid_1's binary_logloss: 0.0922149\n",
      "[350]\ttraining's binary_logloss: 0.0888035\tvalid_1's binary_logloss: 0.092109\n",
      "[375]\ttraining's binary_logloss: 0.088607\tvalid_1's binary_logloss: 0.091976\n",
      "[400]\ttraining's binary_logloss: 0.0884447\tvalid_1's binary_logloss: 0.0918955\n",
      "[425]\ttraining's binary_logloss: 0.0882641\tvalid_1's binary_logloss: 0.0918045\n",
      "[450]\ttraining's binary_logloss: 0.0881465\tvalid_1's binary_logloss: 0.0917756\n",
      "[475]\ttraining's binary_logloss: 0.0880182\tvalid_1's binary_logloss: 0.091737\n",
      "[500]\ttraining's binary_logloss: 0.0878711\tvalid_1's binary_logloss: 0.0916633\n",
      "[525]\ttraining's binary_logloss: 0.0877498\tvalid_1's binary_logloss: 0.0916179\n",
      "[550]\ttraining's binary_logloss: 0.0876288\tvalid_1's binary_logloss: 0.0915844\n",
      "[575]\ttraining's binary_logloss: 0.0875211\tvalid_1's binary_logloss: 0.0915505\n",
      "[600]\ttraining's binary_logloss: 0.0874099\tvalid_1's binary_logloss: 0.0915451\n",
      "Early stopping, best iteration is:\n",
      "[579]\ttraining's binary_logloss: 0.0875043\tvalid_1's binary_logloss: 0.0915441\n",
      "CPU times: user 18min 41s, sys: 1min 30s, total: 20min 11s\n",
      "Wall time: 6min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "params = {'max_depth':5, \n",
    "         'learning_rate':0.05, \n",
    "         'silent':1,\n",
    "         'objective':'binary',\n",
    "         'bagging_freq':1,\n",
    "         'bagging_seed':517,\n",
    "         'bagging_fraction':0.8,\n",
    "         'reg_lambda':3.0, \n",
    "         'reg_alpha':1.0,\n",
    "         'seed':0,\n",
    "         'metric':'binary_logloss'\n",
    "        }\n",
    "n_estimators = 1000\n",
    "model = lgb.train(params, dtrain, valid_sets=[dtrain, dvalid],\n",
    "            early_stopping_rounds=25, num_boost_round=n_estimators, verbose_eval=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = pd.concat([X_train[use_cols], X_val[use_cols]])\n",
    "del X_val\n",
    "y_train = np.concatenate((y_train, y_val))\n",
    "del y_val\n",
    "dtrain = lgb.Dataset(X_train, label=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Итоговая модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16min 53s, sys: 1min 36s, total: 18min 29s\n",
      "Wall time: 6min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "params = {'max_depth':5, \n",
    "         'learning_rate':0.05, \n",
    "         'silent':1,\n",
    "         'objective':'binary',\n",
    "         'bagging_freq':1,\n",
    "         'bagging_seed':517,\n",
    "         'bagging_fraction':0.8,\n",
    "         'reg_lambda':3.0, \n",
    "         'reg_alpha':1.0,\n",
    "         'seed':0,\n",
    "         'metric':'binary_logloss'\n",
    "        }\n",
    "model = lgb.train(params, dtrain, num_boost_round=579)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 59.2 s, sys: 784 ms, total: 59.9 s\n",
      "Wall time: 26.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = model.predict(X_test[use_cols])\n",
    "ans = np.zeros(len(id_test))\n",
    "ans[id_test] = y_pred\n",
    "pd.DataFrame({'_ID_': np.arange(len(id_test)), '_VAL_': ans}).to_csv('submits/final_submit.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
